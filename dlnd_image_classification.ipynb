{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification with CIFAR-10 dataset\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some references to look up\n",
    "- [CIFAR-10/CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html): labeled subsets of the 80 million tiny images dataset. \n",
    "- [urlretrieve lib](https://docs.python.org/3.0/library/urllib.request.html): copy a network object denoted by a URL to a local file, if necessary\n",
    "- [tarfile lib](https://docs.python.org/2/library/tarfile.html): makes it possible to read and write tar archives, including those using gzip or bz2 compression.\n",
    "- [tqdm lib](https://pypi.python.org/pypi/tqdm): Fast, Extensible Progress Meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Jumping in\n",
    "\n",
    "### Some references to look up\n",
    "- [python pickle](https://docs.python.org/3/library/pickle.html): implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "- [numpy reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html): Gives a new shape to an array without changing its data.\n",
    "- [numpy transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html): Permute the dimensions of an array.\n",
    "- [numpy transpose with list of axes explanation](https://stackoverflow.com/questions/32034237/how-does-numpys-transpose-method-permute-the-axes-of-an-array)\n",
    "- [tensorflow conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d): check out input with the argument, data_format. \"NHWC\": [batch, height, width, channels], \"NCHW\": [batch, channels, height, width].\n",
    "- [row major order explanation](https://en.wikipedia.org/wiki/Row-_and_column-major_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of files \n",
    "\n",
    "![](./list_of_batch_files.png)\n",
    "\n",
    "As seen above picture, the dataset is broken into batches to **prevent** your machine from running **out of memory**. The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "\n",
    "### Understanding the original data \n",
    "\n",
    "The original a batch data is (10000 x 3072) dimensional tensor expressed in numpy array, where the number of columns, (10000), indicates the number of sample data. As stated in the [CIFAR-10/CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), the row vector, (3072) represents an color image of 32x32 pixels. Since this project is going to use CNN for the classification tasks, the row vector, (3072), is not an appropriate form of image data to feed. In order to feed an image data into a CNN model, the dimension of the tensor representing an image data should be either (width x height x num_channel) or (num_channel x width x height). It depends on your choice (check out the [tensorflow conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)). In this particular project, I am going to use the dimension of the first choice because the default choice in tensorflow's CNN operation is so.\n",
    "\n",
    "[O] need to be modified into a new shape\n",
    "\n",
    "### Understanding the original labels\n",
    "\n",
    "The label data is just a list of 10000 numbers in the range 0-9, which corresponds to each of the 10 classes in CIFAR-10. \n",
    "\n",
    "* **airplane**\n",
    "* **automobile**\n",
    "* **bird**\n",
    "* **cat**\n",
    "* **deer**\n",
    "* **dog**\n",
    "* **frog**\n",
    "* **horse**\n",
    "* **ship**\n",
    "* **truck**\n",
    "\n",
    "[X] need to be modified into a new shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to reshape into a such form?\n",
    "\n",
    "The row vector (3072) has the exact same number of elements if you calculate 32\\*32\\*3==3072. In order to reshape the row vector, (3072), there are two steps required. The **first** step is involved with using **reshape** function in numpy, and the **second** step is involved with using **transpose** function in numpy as well.\n",
    "\n",
    "By definition from the official web site, **reshape** function gives a new shape to an array without changing its data. Here, the phrase **without changing its data** is an important part. **reshape** operations should be delivered in three more detailed step. The following direction is described in a logical concept. \n",
    "\n",
    "1. divide the row vector (3072) into 3 pieces. Each piece corresponds to the each channels.\n",
    "  - this results in (3 x 1024) dimension of tensor\n",
    "2. divide the resulting tensor from the previous step with 32. 32 here means width of an image.\n",
    "  - this results in (3 x 32 x 32)\n",
    "\n",
    "In order to implement the directions written in logical sense in numpy, **reshape** function should be called in the following arguments, (10000, 3, 32, 32). As you noticed, reshape function doesn't automatically divide further when the third value (32, width) is provided. We need to explicitly specify the value for the last value (32, height)\n",
    "\n",
    "\n",
    "This is not the end of story. Now, the image data is represented as (num_channel, width, height) form. However, **this is not the shape tensorflow and matplotlib are expecting**. They are expecting different shape of (width, height, num_channel) instead. We need to swap the order of each axes, and that is where **transpose** function comes in.\n",
    "\n",
    "The **transpose** function can take a list of axes, and each value specifies where it wants to move around. For example, calling transpose with argument (1, 2, 0) in an numpy array of (num_channel, width, height) will return a new numpy array of (width, height, num_channel).\n",
    "\n",
    "<img src=\"./reshape-transpose.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "The display_stats defined below answers some of questions like in a given batch of data..\n",
    "- \"What are all possible labels?\"\n",
    "- \"What is the range of values for the image data?\"\n",
    "- \"Are the labels in order or random?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkipmo5ckqWI2ekmSKmajlySpYv8frPYn/lYzutcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "**Min-Max Normalization**\n",
    "- this simply makes all x values to range between 0 and 1.\n",
    "- y = (x-min) / (max-min)\n",
    "\n",
    "**Some references to look up**\n",
    "- [Min-Max Normalization](https://www.quora.com/What-is-the-meaning-of-min-max-normalization)\n",
    "- [Watch \"why normalizing inputs\"](https://www.youtube.com/watch?v=FDCfw-YqWTE)\n",
    "- [Exploding, Vainishing Gradient descent](https://www.youtube.com/watch?v=qhXZsFVxGKo)\n",
    "\n",
    "`normalize` function takes an image data, `x`, and returns it as a normalized Numpy array. The values in the original data is going to be transformed in range of 0 to 1, inclusive without change the shape of the array. A simply answer to why normalization should be performed is somewhat related to activation function.\n",
    "\n",
    "For example, sigmoid activation function takes an input value and outputs a new value ranging from 0 to 1. When the input value is somewhat large, the output value easily reaches the max value 1. Similarily, when the input value is somewhat small, the output value easily reaches the max value 0. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "For another example, ReLU activation function takes an input value and outputs a new value ranging from 0 to infinity. When the input value is somewhat large, the output value increases linearly. However, when the input value is somewhat small, the output value easily reaches the max value 0. \n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/Relu.jpeg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Now, when we think about the image data, all values originally ranges from 0 to 255. This sounds like when it is passed into sigmoid function, the output is almost always 1, and when it is passed into ReLu function, the output could be very huge. When backpropagation process is performed to optimize the networks, this could lead to an exploding gradient which leads to an aweful learning steps. In order to avoid this issue, ideally, it is better let all the values be around 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "\n",
    "Since the output of our model is going to show the probabilities of where an image should be categorized as a prediction. There should be a vector having the same number of elements as the number of image classes. For instance, CIFAR-10 provides 10 different classes of image, so we need a vector in size of 10 as well. Each element represents the predicting probability of each classes.\n",
    "\n",
    "Also, our model should be able to compare the prediction with the ground truth label. It means the shape of the label data should also be transformed into a vector in size of 10 too. Instead, because label is the ground truth, we set the value 1 to the corresponding element.\n",
    "\n",
    "**`one_hot_encode`** function takes the input, **`x`**, which is a list of labels(ground truth). The total number of element in the list is the total number of samples in a batch. **`one_hot_encode`** function returns a 2 dimensional tensor, where the number of row is the size of the batch, and the number of column is the number of image classes.\n",
    "\n",
    "#### some references to look up\n",
    "- [one hot encoding](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "\n",
    "The code cell below uses the previously implemented functions, normalize and one_hot_encode, to preprocess the given dataset.\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation. \n",
    "\n",
    "<img src=\"./train-valid-test split.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "\n",
    "#### some references to look up\n",
    "- [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers)\n",
    "- [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)\n",
    "- [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-df210d1950ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mDON\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mT\u001b[0m \u001b[0mMODIFY\u001b[0m \u001b[0mANYTHING\u001b[0m \u001b[0mIN\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mCELL\u001b[0m \u001b[0mTHAT\u001b[0m \u001b[0mIS\u001b[0m \u001b[0mBELOW\u001b[0m \u001b[0mTHIS\u001b[0m \u001b[0mLINE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \"\"\"\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mtests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_con_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2d_maxpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Admin\\Documents\\CIFAR10-img-classification\\problem_unittests.py\u001b[0m in \u001b[0;36mtest_con_pool\u001b[1;34m(conv2d_maxpool)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mtest_pool_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mconv2d_maxpool_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d_maxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_con_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_con_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mconv2d_maxpool_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-df210d1950ed>\u001b[0m in \u001b[0;36mconv2d_maxpool\u001b[1;34m(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0mconvolution\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmax\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m---> 11\u001b[1;33m     weights = tf.Variable(tf.truncated_normal(shape=[conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs], \n\u001b[0m\u001b[0;32m     12\u001b[0m                                                           mean=0, stddev=0.08))\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs], \n",
    "                                                          mean=0, stddev=0.08))\n",
    "    \n",
    "    biases = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    strides = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor,\n",
    "                        weights, \n",
    "                        strides=strides, \n",
    "                        padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.bias_add(conv, biases)\n",
    "    \n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    pool_size = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    \n",
    "    conv = tf.nn.max_pool(conv, \n",
    "                          ksize=pool_size, \n",
    "                          strides=pool_strides, \n",
    "                          padding='SAME')\n",
    "    \n",
    "    return conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,1,1,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=64, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that can be loaded from disk after training\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 128\n",
    "keep_probability = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 1:  "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2085 Validation Accuracy: 0.212600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8107 Validation Accuracy: 0.245600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.7291 Validation Accuracy: 0.313800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.6600 Validation Accuracy: 0.359000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.6590 Validation Accuracy: 0.403200\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.7614 Validation Accuracy: 0.408800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.3296 Validation Accuracy: 0.437200\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.2989 Validation Accuracy: 0.458800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.3421 Validation Accuracy: 0.462400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.3294 Validation Accuracy: 0.503400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.4014 Validation Accuracy: 0.495200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.1166 Validation Accuracy: 0.489800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.0990 Validation Accuracy: 0.510000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.1541 Validation Accuracy: 0.516000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.1766 Validation Accuracy: 0.526400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.1726 Validation Accuracy: 0.528800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.9543 Validation Accuracy: 0.506400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.9643 Validation Accuracy: 0.531800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.0508 Validation Accuracy: 0.540000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.0490 Validation Accuracy: 0.541800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.0761 Validation Accuracy: 0.541600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.7965 Validation Accuracy: 0.510200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.9095 Validation Accuracy: 0.546400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.9491 Validation Accuracy: 0.555800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.0078 Validation Accuracy: 0.541000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.9784 Validation Accuracy: 0.561600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.7497 Validation Accuracy: 0.566400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.7784 Validation Accuracy: 0.562000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.8370 Validation Accuracy: 0.572400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.8416 Validation Accuracy: 0.559800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.8302 Validation Accuracy: 0.571200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.6638 Validation Accuracy: 0.583400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.6446 Validation Accuracy: 0.580800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.8660 Validation Accuracy: 0.582600\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.8008 Validation Accuracy: 0.558000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.7461 Validation Accuracy: 0.580600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.6579 Validation Accuracy: 0.579400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.5446 Validation Accuracy: 0.576600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.7449 Validation Accuracy: 0.573600\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.7350 Validation Accuracy: 0.567200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.7668 Validation Accuracy: 0.582800\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.6056 Validation Accuracy: 0.583000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.4770 Validation Accuracy: 0.570800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.6570 Validation Accuracy: 0.583000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.6285 Validation Accuracy: 0.573600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.6077 Validation Accuracy: 0.586400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.5012 Validation Accuracy: 0.593800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3164bfd669fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-b39bdba8fcae>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[1;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 })\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5882762738853503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
